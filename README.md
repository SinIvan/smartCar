# smartCar
The smart car is a highly computerized automobile featuring ubiquitous computing, intuitive human-computer interaction and an open application platform. Here, we propose an advanced Smart Car demonstration platform with a transparent windshield display and various motion sensors where drivers can manipulate a variety of car-appropriate applications in augmented reality. Similar to smartphones, drivers can customize their Smart Car through free downloads of car-appropriate applications according to their wants and needs. 



![image](https://github.com/smartCarLab/smartCar/blob/master/image/image1.png?raw=true)

Figure 1. Exterior and interior views of the Smart Car demonstration platform. 

(1) Ubicomp for Smart Cars: The in-vehicle system should be networked, autonomously context-aware, and transparently
accessible. Additionally, the system should be able to handle multiple datasets and interactions acquired quickly from
various sensors.

(2) HCI for Smart Cars: The windshield should be replaced entirely by a see-through display while embedding various sensors
to convey information in a straightforward and easy manner.

![image](https://github.com/smartCarLab/smartCar/blob/master/image/image2.png?raw=true)

Figure 2. System architecture of the Smart Car demonstration platform.

(1) Application platform for Smart Cars: The development platform should be opened up. Hence, several car-appropriate
applications from third-party developers would allow users to customize vehicle capabilities and features for their wants
and needs

![image](https://github.com/smartCarLab/smartCar/blob/master/image/image3.png?raw=true)

Figure 3. The Smart Car’s configuration.

(1) Input sensors - vehicle surround sensors: There are six image sensors plus a GPS sensor around the Smart Car
demonstration platform for capturing road scenes and locating the car’s position. The configuration of these image sensors, which jointly offer the driver with a 360-degree view out of the vehicle, is given in the left side of Fig. 4.

(2) Input sensors - user behavioral sensors: In our Smart Car demonstration platform, there are three kinds of motion
sensors (including a gesture sensor, a voice sensor, and an eye-tracking sensor) mounted on the dashboard of the vehicle
which receive user’s commands and transmit them to the computing and communication unit, as shown in the right side
of Fig. 4.

(3) Output devices - transparent windshield display: The Smart Car demonstration platform has a transparent display built
into its windshield. Hence, the windshield acts as a display that allows users to not only see through the screen but
also show on-demand information with real-time display in augmented reality through this visual interface. Here, the
on-demand information refers to the driver’s requests regarding the content of Smart Car’s applications which are made available to driver as needed.

![image](https://github.com/smartCarLab/smartCar/blob/master/image/image4.png?raw=true)

Figure 4. Layout combination of the transparent windshield display

In this section, we implement and discuss three potential applications for Smart Cars related to computer vision which can be used to enhance operational safety. All these three applications were previously developed by the authors of this paper and were adapted to fit into this Smart Car demonstration platform. The icons used for these three applications are given in Table II.

![image](https://github.com/smartCarLab/smartCar/blob/master/image/image5.png?raw=true)

Figure 5. Manipulation of visibility restoration application in the Smart Car. Upper portion:
driving in conditions with poor visibility; mid portion: turning on the visibility restoration application;
lower portion: driver’s vision field has been improved after turning on the application.

(1) Local lights
(2) Colorcast problem
(3) Gray road
(4) Deep depth of fiel
(5) Planar surface
(6) Complex architecture

![image](https://github.com/smartCarLab/smartCar/blob/master/image/image6.png?raw=true)

Figure 6. Driver performing the nighttime contrast enhancement application where the
driver’svision field is increased. Upper and lower portions represent the driver’s vision field
before and after using the application.

TABLE IV: Challenges and solutions for image contrast enhancement algorithms when driving at night. The first column lists the challenges and the second column lists the corresponding solutions

